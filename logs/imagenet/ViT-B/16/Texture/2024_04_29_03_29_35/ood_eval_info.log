2024-04-29 03:29:35,058 : #########TRAIN_EVAL_INFO############
2024-04-29 03:29:35,114 : 
Running in-domain dataset configs.
2024-04-29 03:29:35,114 : {'root_path': '/home/nfs03/liyh/', 'seed': 3407, 'load_cache': True, 'load_pre_feat': True, 'search_hp': True, 'search_scale': [30, 30, 60], 'search_step': [200, 30, 40], 'init_beta': 1, 'init_alpha': 2, 'init_gamma': 0.1, 'eps': 0.001, 'training_feat_num': 256, 'training_free_feat_num': 256, 'w_training_free': [0.7, 0.3], 'w_training': [0.2, 0.8], 'dataset': 'imagenet', 'shots': 16, 'backbone': 'ViT-B/16', 'lr': 0.001, 'augment_epoch': 10, 'train_epoch': 20, 'data_section': 0, 'cache_dir': '/home/nfs03/zengtc/tip/caches/imagenet'}
2024-04-29 03:29:41,953 : Preparing ImageNet dataset.
2024-04-29 03:38:11,516 : Getting textual features as CLIP's classifier.
2024-04-29 03:38:27,816 : 
Constructing cache model by few-shot visual features and labels.
2024-04-29 03:38:27,841 : 
Loading visual features and labels from test set.
2024-04-29 03:38:27,868 : 
Running out-domain dataset configs.
2024-04-29 03:38:27,868 : {'root_path': '/home/nfs03/zengtc', 'load_cache': False, 'load_pre_feat': False, 'dataset': 'Texture', 'backbone': 'ViT-B/16'}
2024-04-29 03:38:37,291 : **** pos test accuracy: 68.76. ****

2024-04-29 03:38:37,295 : **** neg test accuracy: 0.00. ****

2024-04-29 03:38:37,299 : **** neg test accuracy: 57.97. ****

2024-04-29 03:38:37,302 : **** dual test accuracy: 22.84. ****

2024-04-29 03:38:37,626 : **** Our's test pos auroc: 87.82, fpr: 52.93. ****

2024-04-29 03:38:37,973 : **** Our's test neg(-) auroc: 71.23, fpr: 80.82. ****

2024-04-29 03:38:38,321 : **** Our's test neg(+) auroc: 86.34, fpr: 57.07. ****

2024-04-29 03:38:38,666 : **** Our's test dual auroc: 73.65, fpr: 76.72. ****

2024-04-29 03:38:39,110 : **** Our's test dual-ours auroc : 86.99, fpr: 54.77. ****

